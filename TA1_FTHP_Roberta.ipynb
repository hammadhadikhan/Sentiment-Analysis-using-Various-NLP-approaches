{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "aVpKIfhcvgmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_EeGBd1QohT",
        "outputId": "97bdb5d4-dd85-4d94-cecb-0a2993aa1a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "/usr/bin/xdg-open: 882: www-browser: not found\n",
            "/usr/bin/xdg-open: 882: links2: not found\n",
            "/usr/bin/xdg-open: 882: elinks: not found\n",
            "/usr/bin/xdg-open: 882: links: not found\n",
            "/usr/bin/xdg-open: 882: lynx: not found\n",
            "/usr/bin/xdg-open: 882: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=wjshyaUWMZscDPkurgNiO2h2xqtf785pMPVDtGD-gtI'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/usr/bin/open: 882: www-browser: not found\n",
            "/usr/bin/open: 882: links2: not found\n",
            "/usr/bin/open: 882: elinks: not found\n",
            "/usr/bin/open: 882: links: not found\n",
            "/usr/bin/open: 882: lynx: not found\n",
            "/usr/bin/open: 882: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=wjshyaUWMZscDPkurgNiO2h2xqtf785pMPVDtGD-gtI'\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=wjshyaUWMZscDPkurgNiO2h2xqtf785pMPVDtGD-gtI\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgeYp3yTSG_8",
        "outputId": "bea2a580-d466-4f97-cde1-2a33ba41cb83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package w3m.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 121754 files and directories currently installed.)\n",
            "Preparing to unpack .../w3m_0.5.3+git20210102-6ubuntu0.2_amd64.deb ...\n",
            "Unpacking w3m (0.5.3+git20210102-6ubuntu0.2) ...\n",
            "Setting up w3m (0.5.3+git20210102-6ubuntu0.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK5hsu4bOtfQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U bitsandbytes\n",
        "%pip install -U transformers\n",
        "%pip install -U peft\n",
        "%pip install -U accelerate\n",
        "%pip install -U trl\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install wandb\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "NevlS1a4Pn6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datasets\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification,Trainer, TrainingArguments\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import os\n",
        "import re\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "import os,torch, wandb\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8aPV5S_PBn8",
        "outputId": "012a99e4-1679-4234-b8c0-768f91d805ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hf_token = \"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\"\n",
        "# wandb_key = \"1a42824747ccabf69094fd7e7ece965480af2b41\""
      ],
      "metadata": {
        "id": "qqlVNDr6PXgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli login --token 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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgNlBA8DP41D",
        "outputId": "02da97e7-feff-418f-d761-ab55d6585a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.login(key = \"1a42824747ccabf69094fd7e7ece965480af2b41\")\n",
        "# run = wandb.init(\n",
        "#     project='Fine tuning Roberta1 TA A1',\n",
        "#     job_type=\"training\",\n",
        "#     anonymous=\"allow\"\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "45kXGXz9P7W9",
        "outputId": "8977cf3f-99a6-4dd7-b7d5-d894e0fd85ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbilalnaseem1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240223_171514-f8ajukf4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bilalnaseem1/Fine%20tuning%20Roberta1%20TA%20A1/runs/f8ajukf4' target=\"_blank\">virtuous-rooster-3</a></strong> to <a href='https://wandb.ai/bilalnaseem1/Fine%20tuning%20Roberta1%20TA%20A1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bilalnaseem1/Fine%20tuning%20Roberta1%20TA%20A1' target=\"_blank\">https://wandb.ai/bilalnaseem1/Fine%20tuning%20Roberta1%20TA%20A1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bilalnaseem1/Fine%20tuning%20Roberta1%20TA%20A1/runs/f8ajukf4' target=\"_blank\">https://wandb.ai/bilalnaseem1/Fine%20tuning%20Roberta1%20TA%20A1/runs/f8ajukf4</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/train.csv')\n",
        "test_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/test.csv')\n",
        "\n",
        "train_dataset['label'] = [1 if x==\"positive\" else 0 for x in train_dataset['sentiment'] ]\n",
        "test_dataset['label'] = [1 if x==\"positive\" else 0 for x in test_dataset['sentiment'] ]\n",
        "\n",
        "train_dataset = train_dataset.drop('sentiment', axis=1)\n",
        "test_dataset = test_dataset.drop('sentiment', axis=1)\n",
        "\n",
        "def cleaning(s):\n",
        "    s = str(s)\n",
        "    s = s.replace(\"<br />\", \" \")\n",
        "    s = re.sub('\\s\\W',' ',s)\n",
        "    s = re.sub('\\W,\\s',' ',s)\n",
        "    s = re.sub(\"\\d+\", \"\", s)\n",
        "    s = re.sub('\\s+',' ',s)\n",
        "    s = re.sub('[!@#$_]', '', s)\n",
        "    s = s.replace(\"co\",\"\")\n",
        "    s = s.replace(\"https\",\"\")\n",
        "    s = s.replace(\"[\\w*\",\" \")\n",
        "    s = s.replace(\".:\",\" \")\n",
        "    return s\n",
        "\n",
        "test_dataset['review'] = test_dataset['review'].apply(cleaning)\n",
        "train_dataset['review'] = train_dataset['review'].apply(cleaning)\n",
        "\n",
        "train_texts, train_labels = train_dataset['review'], train_dataset['label']\n",
        "test_texts, test_labels = test_dataset['review'], test_dataset['label']\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "test_texts.reset_index(drop=True, inplace=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "val_texts.reset_index(drop=True, inplace=True)\n",
        "train_labels.reset_index(drop=True, inplace=True)\n",
        "val_labels.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "aQS-SCmEwWfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', max_length = 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu9RtxfXwWcY",
        "outputId": "41e15a0c-6b1e-40f7-e88d-62d98069d35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "fCgPj_sjwWZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class IMDBdataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "        # Ensure all encodings and labels have consistent lengths\n",
        "        assert all(len(val) == len(self.labels) for val in self.encodings.values()), \"Encodings and labels lengths do not match.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ],
      "metadata": {
        "id": "Q-ggEowmwWXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = IMDBdataset(train_encodings, train_labels)\n",
        "test_dataset = IMDBdataset(test_encodings,test_labels)\n",
        "val_dataset = IMDBdataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "7JXce-0owWUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "Oyqucc1BwWR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "\n",
        "optim = AdamW(model.parameters(),lr=5e-5)\n",
        "\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "\n",
        "total_start_time = time.time()  # Start timing for the total training time\n",
        "\n",
        "\n",
        "for epoch in range(3):\n",
        "    epoch_start_time = time.time()  # Start timing for the epoch\n",
        "\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_loss = 0\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_dataloader)  # Calculate the average loss over all training batches\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():  # Do not compute gradient to speed up computation and reduce memory usage\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs[0]\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_dataloader)  # Calculate the average loss over all validation batches\n",
        "\n",
        "    epoch_end_time = time.time()  # End timing for the epoch\n",
        "\n",
        "    # Print the losses and the time taken for the epoch\n",
        "    print(f\"Epoch {epoch+1}/{3}: Train loss = {train_loss:.4f}, Validation loss = {val_loss:.4f}\")\n",
        "    print(f\"Time taken for epoch {epoch+1}: {epoch_end_time - epoch_start_time:.2f} seconds\")\n",
        "\n",
        "total_end_time = time.time()  # End timing for the total training time\n",
        "print(f\"Total training time: {total_end_time - total_start_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "KEjg29PVwWPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory = \"/content/drive/MyDrive/TA/A1/FT_Roberta1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y4Bu622Wx9kn",
        "outputId": "aaa46a33-37ca-4a1b-f58d-778b9e83bafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "UTtx3mEEx9h4",
        "outputId": "c7a1726f-e7bd-4b18-804c-09f3613d6316"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 501/4500 12:35 < 1:40:55, 0.66 it/s, Epoch 0.33/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(save_directory, return_dict=False).to(device)"
      ],
      "metadata": {
        "id": "L6sVXWKNx9fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "model.eval()  # Ensure the model is in evaluation mode\n",
        "\n",
        "# Store predictions and actual labels\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        # Move tensors to the same device as the model\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)  # Only needed if you're also evaluating performance\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Assuming you're doing classification and want the highest probability class\n",
        "        logits = outputs[0]\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "        predictions.extend(predicted_labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "MX9JKl6Ox9Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        labels = batch['labels'].to(device)  # Assuming labels are on the same device\n",
        "        actual_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "iGLLYNHtx9Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = sum(p == a for p, a in zip(predictions, actual_labels))\n",
        "accuracy = correct_predictions / len(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "dp7oAIoNx9N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
        "\n",
        "# Ensure predictions and actual_labels are numpy arrays or compatible formats\n",
        "precision = precision_score(actual_labels, predictions)\n",
        "recall = recall_score(actual_labels, predictions)\n",
        "f1 = f1_score(actual_labels, predictions)\n",
        "conf_matrix = confusion_matrix(actual_labels, predictions)\n",
        "mcc = matthews_corrcoef(actual_labels, predictions)\n",
        "\n",
        "# ROC-AUC score requires probability scores of the positive class, which might need model.predict_proba() or equivalent\n",
        "# If your model outputs probabilities, you can use:\n",
        "# roc_auc = roc_auc_score(actual_labels, prediction_probabilities)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.2f}\")\n",
        "# print(f\"ROC-AUC Score: {roc_auc:.2f}\")  # Uncomment if you have probability predictions\n"
      ],
      "metadata": {
        "id": "meahEA5Fx9LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJIxEbnjx9CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T6nxR955wWMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05znbejMQGmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GZ1oGhdoQlRC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}