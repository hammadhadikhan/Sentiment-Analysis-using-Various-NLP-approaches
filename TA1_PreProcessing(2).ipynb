{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install -U bitsandbytes\n",
        "%pip install -U transformers\n",
        "%pip install -U peft\n",
        "%pip install -U accelerate\n",
        "%pip install -U trl"
      ],
      "metadata": {
        "id": "KPKP15wqW0Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "# !pip install wandb\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "mCYRlUeKW0PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9HwkVHGeVpq",
        "outputId": "7ada6022-deb4-470b-d528-e6afdb13eb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "/usr/bin/xdg-open: 882: www-browser: not found\n",
            "/usr/bin/xdg-open: 882: links2: not found\n",
            "/usr/bin/xdg-open: 882: elinks: not found\n",
            "/usr/bin/xdg-open: 882: links: not found\n",
            "/usr/bin/xdg-open: 882: lynx: not found\n",
            "/usr/bin/xdg-open: 882: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=6dfRQxYk6nf45ATmnCqctMd5lS0YfjaBYNavxeWFdIk'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/usr/bin/open: 882: www-browser: not found\n",
            "/usr/bin/open: 882: links2: not found\n",
            "/usr/bin/open: 882: elinks: not found\n",
            "/usr/bin/open: 882: links: not found\n",
            "/usr/bin/open: 882: lynx: not found\n",
            "/usr/bin/open: 882: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=6dfRQxYk6nf45ATmnCqctMd5lS0YfjaBYNavxeWFdIk'\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=6dfRQxYk6nf45ATmnCqctMd5lS0YfjaBYNavxeWFdIk\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h22KDRLCf3Sd",
        "outputId": "23d1587e-0256-4e1c-95cf-edc394c67ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package w3m.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 121754 files and directories currently installed.)\n",
            "Preparing to unpack .../w3m_0.5.3+git20210102-6ubuntu0.2_amd64.deb ...\n",
            "Unpacking w3m (0.5.3+git20210102-6ubuntu0.2) ...\n",
            "Setting up w3m (0.5.3+git20210102-6ubuntu0.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall contractions\n",
        "# clear_output()"
      ],
      "metadata": {
        "id": "Wpf0FvXgnPB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datasets\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification,Trainer, TrainingArguments\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "# import wandb\n",
        "import os\n",
        "import re\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "import os,torch\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from contractions import CONTRACTION_MAP\n",
        "import unicodedata\n",
        "\n",
        "# nlp = spacy.load('en', parse = False, tag=False, entity=False)\n",
        "tokenizer = ToktokTokenizer()\n",
        "# stopword_list = nltk.corpus.stopwords.words('english')\n",
        "# stopword_list.remove('no')\n",
        "# stopword_list.remove('not')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "A9GbFLVnW0Mn",
        "outputId": "d8efdacb-33a5-4186-9f85-00d85c69c5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'CONTRACTION_MAP' from 'contractions' (/usr/local/lib/python3.10/dist-packages/contractions/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-c95765c045c8>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcontractions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONTRACTION_MAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'CONTRACTION_MAP' from 'contractions' (/usr/local/lib/python3.10/dist-packages/contractions/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!wget https://raw.githubusercontent.com/Puspita-111/Suven-consultants-and-technology/main/contractions.py\n",
        "!wget https://raw.githubusercontent.com/Puspita-111/Suven-consultants-and-technology/main/text_normalizer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heVOKT47s5k3",
        "outputId": "abb9f3a9-c24b-4413-82b6-5ee6b3d690bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNCZz8Z5s_gz",
        "outputId": "89c88d21-474f-41ea-bcdf-12f5fc04cff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contractions.py  drive\tsample_data  text_normalizer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv contractions.py /content/"
      ],
      "metadata": {
        "id": "E30L41QbsIt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /text_normalizer.py /content/"
      ],
      "metadata": {
        "id": "Q8JDCGljsx0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj32qZiMrBfg",
        "outputId": "79fca353-e9bc-4a2d-b86b-41178ecfa636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-24 10:38:53--  https://raw.githubusercontent.com/Puspita-111/Suven-consultants-and-technology/main/contractions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3110 (3.0K) [text/plain]\n",
            "Saving to: ‘contractions.py.4’\n",
            "\n",
            "\rcontractions.py.4     0%[                    ]       0  --.-KB/s               \rcontractions.py.4   100%[===================>]   3.04K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-24 10:38:53 (51.0 MB/s) - ‘contractions.py.4’ saved [3110/3110]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "6gYjzN8frF37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trial 1"
      ],
      "metadata": {
        "id": "IkFe-Wu-iq_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/train.csv')\n",
        "test_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/test.csv')\n",
        "\n",
        "train_dataset['label'] = [1 if x==\"positive\" else 0 for x in train_dataset['sentiment'] ]\n",
        "test_dataset['label'] = [1 if x==\"positive\" else 0 for x in test_dataset['sentiment'] ]\n",
        "\n",
        "train_dataset = train_dataset.drop('sentiment', axis=1)\n",
        "test_dataset = test_dataset.drop('sentiment', axis=1)\n",
        "\n",
        "train_texts, train_labels = train_dataset['review'], train_dataset['label']\n",
        "test_texts, test_labels = test_dataset['review'], test_dataset['label']\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "test_texts.reset_index(drop=True, inplace=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "val_texts.reset_index(drop=True, inplace=True)\n",
        "train_labels.reset_index(drop=True, inplace=True)\n",
        "val_labels.reset_index(drop=True, inplace=True)\n",
        "\n",
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
        "\n",
        "import torch\n",
        "\n",
        "class IMDBdataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "        # Ensure all encodings and labels have consistent lengths\n",
        "        assert all(len(val) == len(self.labels) for val in self.encodings.values()), \"Encodings and labels lengths do not match.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = IMDBdataset(train_encodings, train_labels)\n",
        "test_dataset = IMDBdataset(test_encodings,test_labels)\n",
        "val_dataset = IMDBdataset(val_encodings, val_labels)\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model = model.to(device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUyxOkoYW0KN",
        "outputId": "c491aa6b-51aa-43dc-948d-2e137a5e3513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "pz9tL4qMgY0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "raw_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "raw_model = raw_model.to(device=device)\n",
        "raw_model.eval()\n",
        "\n",
        "\n",
        "# Store predictions and actual labels\n",
        "raw_predictions = []\n",
        "raw_actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        # Move tensors to the same device as the model\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)  # Only needed if you're also evaluating performance\n",
        "\n",
        "        outputs = raw_model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Assuming you're doing classification and want the highest probability class\n",
        "        logits = outputs[0]\n",
        "        raw_predicted_labels = torch.argmax(logits, dim=1)\n",
        "        raw_predictions.extend(raw_predicted_labels.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_XuYv1VXA3I",
        "outputId": "33a47e32-43a4-4e05-974e-fb462dfffbe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 20000/20000 [05:51<00:00, 56.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_actual_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        raw_labels = batch['labels'].to(device)  # Assuming labels are on the same device\n",
        "        raw_actual_labels.extend(raw_labels.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu4gh759XA0N",
        "outputId": "c8001794-e7cf-40e4-c040-1e47c928a731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [00:07<00:00, 2549.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_correct_predictions = sum(p == a for p, a in zip(raw_predictions, raw_actual_labels))\n",
        "raw_accuracy = raw_correct_predictions / len(raw_predictions)\n",
        "print(f\"Accuracy: {raw_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAsYrZTmXAxm",
        "outputId": "aa470aa2-e5c1-4e81-cff9-baffe5718d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 53.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
        "# Ensure predictions and actual_labels are numpy arrays or compatible formats\n",
        "precision = precision_score(raw_actual_labels, raw_predictions)\n",
        "recall = recall_score(raw_actual_labels, raw_predictions)\n",
        "f1 = f1_score(raw_actual_labels, raw_predictions)\n",
        "conf_matrix = confusion_matrix(raw_actual_labels, raw_predictions)\n",
        "mcc = matthews_corrcoef(raw_actual_labels, raw_predictions)\n",
        "\n",
        "# ROC-AUC score requires probability scores of the positive class, which might need model.predict_proba() or equivalent\n",
        "# If your model outputs probabilities, you can use:\n",
        "# roc_auc = roc_auc_score(actual_labels, prediction_probabilities)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.2f}\")\n",
        "# print(f\"ROC-AUC Score: {roc_auc:.2f}\")  # Uncomment if you have probability predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKmuV8yUXAu_",
        "outputId": "b9f42db4-476b-4cc0-fdcf-983c8047e970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.57\n",
            "Recall: 0.31\n",
            "F1 Score: 0.40\n",
            "Confusion Matrix:\n",
            "[[7606 2329]\n",
            " [6978 3087]]\n",
            "Matthews Correlation Coefficient: 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "\n",
        "# Fit and transform the training data to create TF-IDF vectors\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
        "\n",
        "# Transform the test data to TF-IDF vectors\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_texts)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef\n",
        "\n",
        "# Initialize and train the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_tfidf, train_labels)\n",
        "\n",
        "# Predict on the test set\n",
        "nb_predictions = nb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Compute metrics\n",
        "nb_accuracy = accuracy_score(test_labels, nb_predictions)\n",
        "nb_precision = precision_score(test_labels, nb_predictions, average='binary')\n",
        "nb_recall = recall_score(test_labels, nb_predictions, average='binary')\n",
        "nb_f1 = f1_score(test_labels, nb_predictions, average='binary')\n",
        "nb_conf_matrix = confusion_matrix(test_labels, nb_predictions)\n",
        "nb_mcc = matthews_corrcoef(test_labels, nb_predictions)\n",
        "\n",
        "print(\"Naive Bayes Metrics:\")\n",
        "print(f\"Accuracy: {nb_accuracy:.4f}\")\n",
        "print(f\"Precision: {nb_precision:.4f}\")\n",
        "print(f\"Recall: {nb_recall:.4f}\")\n",
        "print(f\"F1 Score: {nb_f1:.4f}\")\n",
        "print(f\"Confusion Matrix: \\n{nb_conf_matrix}\")\n",
        "print(f\"Matthews Correlation Coefficient: {nb_mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQKkDfPYXAsf",
        "outputId": "859c8969-2482-46a2-f682-547e6a479174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Metrics:\n",
            "Accuracy: 0.8612\n",
            "Precision: 0.8674\n",
            "Recall: 0.8549\n",
            "F1 Score: 0.8611\n",
            "Confusion Matrix: \n",
            "[[8620 1315]\n",
            " [1460 8605]]\n",
            "Matthews Correlation Coefficient: 0.7226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2albp0AtXAqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IKhINXOtW0HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trial 2"
      ],
      "metadata": {
        "id": "T4y7i2eli5Sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "train_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/train.csv')\n",
        "test_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/test.csv')\n",
        "\n",
        "train_dataset['label'] = [1 if x==\"positive\" else 0 for x in train_dataset['sentiment'] ]\n",
        "test_dataset['label'] = [1 if x==\"positive\" else 0 for x in test_dataset['sentiment'] ]\n",
        "\n",
        "train_dataset = train_dataset.drop('sentiment', axis=1)\n",
        "test_dataset = test_dataset.drop('sentiment', axis=1)\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    stripped_text = soup.get_text()\n",
        "    return stripped_text\n",
        "\n",
        "test_dataset['review'] = test_dataset['review'].apply(strip_html_tags)\n",
        "train_dataset['review'] = train_dataset['review'].apply(strip_html_tags)\n",
        "\n",
        "train_texts, train_labels = train_dataset['review'], train_dataset['label']\n",
        "test_texts, test_labels = test_dataset['review'], test_dataset['label']\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "test_texts.reset_index(drop=True, inplace=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "val_texts.reset_index(drop=True, inplace=True)\n",
        "train_labels.reset_index(drop=True, inplace=True)\n",
        "val_labels.reset_index(drop=True, inplace=True)\n",
        "\n",
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
        "\n",
        "import torch\n",
        "\n",
        "class IMDBdataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "        # Ensure all encodings and labels have consistent lengths\n",
        "        assert all(len(val) == len(self.labels) for val in self.encodings.values()), \"Encodings and labels lengths do not match.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = IMDBdataset(train_encodings, train_labels)\n",
        "test_dataset = IMDBdataset(test_encodings,test_labels)\n",
        "val_dataset = IMDBdataset(val_encodings, val_labels)\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model = model.to(device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14362880-7c02-46c1-d951-77af0ddd8c47",
        "id": "4V8ZG5gsi5Ss"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ccb7caa29d84>:13: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "-9WZzYaci5Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "raw_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "raw_model = raw_model.to(device=device)\n",
        "raw_model.eval()\n",
        "\n",
        "\n",
        "# Store predictions and actual labels\n",
        "raw_predictions = []\n",
        "raw_actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        # Move tensors to the same device as the model\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)  # Only needed if you're also evaluating performance\n",
        "\n",
        "        outputs = raw_model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Assuming you're doing classification and want the highest probability class\n",
        "        logits = outputs[0]\n",
        "        raw_predicted_labels = torch.argmax(logits, dim=1)\n",
        "        raw_predictions.extend(raw_predicted_labels.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c75e10-c53d-4eaf-da02-dfa4d39fd978",
        "id": "CO2tLocLi5Sy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 20000/20000 [06:00<00:00, 55.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_actual_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        raw_labels = batch['labels'].to(device)  # Assuming labels are on the same device\n",
        "        raw_actual_labels.extend(raw_labels.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3edcbc0d-d84c-4ca3-9624-27053679365f",
        "id": "kVLxH5mui5Sz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [00:07<00:00, 2522.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_correct_predictions = sum(p == a for p, a in zip(raw_predictions, raw_actual_labels))\n",
        "raw_accuracy = raw_correct_predictions / len(raw_predictions)\n",
        "print(f\"Accuracy: {raw_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f626b63a-2501-4bfe-e6db-a5c2f8811205",
        "id": "JKG6-Dc-i5S0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
        "# Ensure predictions and actual_labels are numpy arrays or compatible formats\n",
        "precision = precision_score(raw_actual_labels, raw_predictions)\n",
        "recall = recall_score(raw_actual_labels, raw_predictions)\n",
        "f1 = f1_score(raw_actual_labels, raw_predictions)\n",
        "conf_matrix = confusion_matrix(raw_actual_labels, raw_predictions)\n",
        "mcc = matthews_corrcoef(raw_actual_labels, raw_predictions)\n",
        "\n",
        "# ROC-AUC score requires probability scores of the positive class, which might need model.predict_proba() or equivalent\n",
        "# If your model outputs probabilities, you can use:\n",
        "# roc_auc = roc_auc_score(actual_labels, prediction_probabilities)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.2f}\")\n",
        "# print(f\"ROC-AUC Score: {roc_auc:.2f}\")  # Uncomment if you have probability predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c979d6-7326-4614-cf3d-4ec65a12d414",
        "id": "9UH5Tccai5S1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.60\n",
            "Recall: 0.02\n",
            "F1 Score: 0.04\n",
            "Confusion Matrix:\n",
            "[[9801  134]\n",
            " [9865  200]]\n",
            "Matthews Correlation Coefficient: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "\n",
        "# Fit and transform the training data to create TF-IDF vectors\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
        "\n",
        "# Transform the test data to TF-IDF vectors\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_texts)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef\n",
        "\n",
        "# Initialize and train the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_tfidf, train_labels)\n",
        "\n",
        "# Predict on the test set\n",
        "nb_predictions = nb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Compute metrics\n",
        "nb_accuracy = accuracy_score(test_labels, nb_predictions)\n",
        "nb_precision = precision_score(test_labels, nb_predictions, average='binary')\n",
        "nb_recall = recall_score(test_labels, nb_predictions, average='binary')\n",
        "nb_f1 = f1_score(test_labels, nb_predictions, average='binary')\n",
        "nb_conf_matrix = confusion_matrix(test_labels, nb_predictions)\n",
        "nb_mcc = matthews_corrcoef(test_labels, nb_predictions)\n",
        "\n",
        "print(\"Naive Bayes Metrics:\")\n",
        "print(f\"Accuracy: {nb_accuracy:.4f}\")\n",
        "print(f\"Precision: {nb_precision:.4f}\")\n",
        "print(f\"Recall: {nb_recall:.4f}\")\n",
        "print(f\"F1 Score: {nb_f1:.4f}\")\n",
        "print(f\"Confusion Matrix: \\n{nb_conf_matrix}\")\n",
        "print(f\"Matthews Correlation Coefficient: {nb_mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnbzVeuwi5S1",
        "outputId": "a432ad40-3b17-4add-df6f-eca2d753749d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Metrics:\n",
            "Accuracy: 0.8599\n",
            "Precision: 0.8622\n",
            "Recall: 0.8590\n",
            "F1 Score: 0.8606\n",
            "Confusion Matrix: \n",
            "[[8553 1382]\n",
            " [1419 8646]]\n",
            "Matthews Correlation Coefficient: 0.7199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trial 3 - Removing accented characters"
      ],
      "metadata": {
        "id": "-zGFlGmYmlAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "train_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/train.csv')\n",
        "test_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/test.csv')\n",
        "\n",
        "train_dataset['label'] = [1 if x==\"positive\" else 0 for x in train_dataset['sentiment'] ]\n",
        "test_dataset['label'] = [1 if x==\"positive\" else 0 for x in test_dataset['sentiment'] ]\n",
        "\n",
        "train_dataset = train_dataset.drop('sentiment', axis=1)\n",
        "test_dataset = test_dataset.drop('sentiment', axis=1)\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "test_dataset['review'] = test_dataset['review'].apply(remove_accented_chars)\n",
        "train_dataset['review'] = train_dataset['review'].apply(remove_accented_chars)\n",
        "\n",
        "train_texts, train_labels = train_dataset['review'], train_dataset['label']\n",
        "test_texts, test_labels = test_dataset['review'], test_dataset['label']\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "test_texts.reset_index(drop=True, inplace=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "val_texts.reset_index(drop=True, inplace=True)\n",
        "train_labels.reset_index(drop=True, inplace=True)\n",
        "val_labels.reset_index(drop=True, inplace=True)\n",
        "\n",
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
        "\n",
        "import torch\n",
        "\n",
        "class IMDBdataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "        # Ensure all encodings and labels have consistent lengths\n",
        "        assert all(len(val) == len(self.labels) for val in self.encodings.values()), \"Encodings and labels lengths do not match.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = IMDBdataset(train_encodings, train_labels)\n",
        "test_dataset = IMDBdataset(test_encodings,test_labels)\n",
        "val_dataset = IMDBdataset(val_encodings, val_labels)\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model = model.to(device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c017d845-1364-4b14-fa1f-32d08103a71c",
        "id": "vRa5unFnmlA1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "Cy2DSSjxmlA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "raw_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "raw_model = raw_model.to(device=device)\n",
        "raw_model.eval()\n",
        "\n",
        "\n",
        "# Store predictions and actual labels\n",
        "raw_predictions = []\n",
        "raw_actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        # Move tensors to the same device as the model\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)  # Only needed if you're also evaluating performance\n",
        "\n",
        "        outputs = raw_model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Assuming you're doing classification and want the highest probability class\n",
        "        logits = outputs[0]\n",
        "        raw_predicted_labels = torch.argmax(logits, dim=1)\n",
        "        raw_predictions.extend(raw_predicted_labels.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3098c031-9d0f-45a6-f9ee-d3aba4795373",
        "id": "ff1AhY2jmlA5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 20000/20000 [06:04<00:00, 54.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_actual_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        raw_labels = batch['labels'].to(device)  # Assuming labels are on the same device\n",
        "        raw_actual_labels.extend(raw_labels.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc1b5e8-27a8-4fbc-93d7-1296026d5884",
        "id": "S3XYaGSomlA7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [00:06<00:00, 2860.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_correct_predictions = sum(p == a for p, a in zip(raw_predictions, raw_actual_labels))\n",
        "raw_accuracy = raw_correct_predictions / len(raw_predictions)\n",
        "print(f\"Accuracy: {raw_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b666b6c-1cd5-44f3-981e-c9fcd90212bc",
        "id": "Xzg8AAvtmlA8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 49.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
        "# Ensure predictions and actual_labels are numpy arrays or compatible formats\n",
        "precision = precision_score(raw_actual_labels, raw_predictions)\n",
        "recall = recall_score(raw_actual_labels, raw_predictions)\n",
        "f1 = f1_score(raw_actual_labels, raw_predictions)\n",
        "conf_matrix = confusion_matrix(raw_actual_labels, raw_predictions)\n",
        "mcc = matthews_corrcoef(raw_actual_labels, raw_predictions)\n",
        "\n",
        "# ROC-AUC score requires probability scores of the positive class, which might need model.predict_proba() or equivalent\n",
        "# If your model outputs probabilities, you can use:\n",
        "# roc_auc = roc_auc_score(actual_labels, prediction_probabilities)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.2f}\")\n",
        "# print(f\"ROC-AUC Score: {roc_auc:.2f}\")  # Uncomment if you have probability predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96d54f9-a885-4fa0-f341-ff3b0c495ad4",
        "id": "BrFnN6XimlA9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.50\n",
            "Recall: 0.98\n",
            "F1 Score: 0.66\n",
            "Confusion Matrix:\n",
            "[[  60 9875]\n",
            " [ 157 9908]]\n",
            "Matthews Correlation Coefficient: -0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "\n",
        "# Fit and transform the training data to create TF-IDF vectors\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
        "\n",
        "# Transform the test data to TF-IDF vectors\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_texts)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef\n",
        "\n",
        "# Initialize and train the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_tfidf, train_labels)\n",
        "\n",
        "# Predict on the test set\n",
        "nb_predictions = nb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Compute metrics\n",
        "nb_accuracy = accuracy_score(test_labels, nb_predictions)\n",
        "nb_precision = precision_score(test_labels, nb_predictions, average='binary')\n",
        "nb_recall = recall_score(test_labels, nb_predictions, average='binary')\n",
        "nb_f1 = f1_score(test_labels, nb_predictions, average='binary')\n",
        "nb_conf_matrix = confusion_matrix(test_labels, nb_predictions)\n",
        "nb_mcc = matthews_corrcoef(test_labels, nb_predictions)\n",
        "\n",
        "print(\"Naive Bayes Metrics:\")\n",
        "print(f\"Accuracy: {nb_accuracy:.4f}\")\n",
        "print(f\"Precision: {nb_precision:.4f}\")\n",
        "print(f\"Recall: {nb_recall:.4f}\")\n",
        "print(f\"F1 Score: {nb_f1:.4f}\")\n",
        "print(f\"Confusion Matrix: \\n{nb_conf_matrix}\")\n",
        "print(f\"Matthews Correlation Coefficient: {nb_mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c128e983-90b3-4e3f-fe72-98d0f85acdc2",
        "id": "hE3fdyj1mlA9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Metrics:\n",
            "Accuracy: 0.8603\n",
            "Precision: 0.8611\n",
            "Recall: 0.8613\n",
            "F1 Score: 0.8612\n",
            "Confusion Matrix: \n",
            "[[8537 1398]\n",
            " [1396 8669]]\n",
            "Matthews Correlation Coefficient: 0.7206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfqtfrB7nyOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trial 4"
      ],
      "metadata": {
        "id": "f8Gy3f4Sr6Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "train_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/train.csv')\n",
        "test_dataset = pd.read_csv('/content/drive/MyDrive/TA/A1/test.csv')\n",
        "\n",
        "train_dataset['label'] = [1 if x==\"positive\" else 0 for x in train_dataset['sentiment'] ]\n",
        "test_dataset['label'] = [1 if x==\"positive\" else 0 for x in test_dataset['sentiment'] ]\n",
        "\n",
        "train_dataset = train_dataset.drop('sentiment', axis=1)\n",
        "test_dataset = test_dataset.drop('sentiment', axis=1)\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "test_dataset['review'] = test_dataset['review'].apply(remove_accented_chars)\n",
        "train_dataset['review'] = train_dataset['review'].apply(remove_accented_chars)\n",
        "\n",
        "train_texts, train_labels = train_dataset['review'], train_dataset['label']\n",
        "test_texts, test_labels = test_dataset['review'], test_dataset['label']\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "test_texts.reset_index(drop=True, inplace=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
        "\n",
        "train_texts.reset_index(drop=True, inplace=True)\n",
        "val_texts.reset_index(drop=True, inplace=True)\n",
        "train_labels.reset_index(drop=True, inplace=True)\n",
        "val_labels.reset_index(drop=True, inplace=True)\n",
        "\n",
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
        "\n",
        "import torch\n",
        "\n",
        "class IMDBdataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "        # Ensure all encodings and labels have consistent lengths\n",
        "        assert all(len(val) == len(self.labels) for val in self.encodings.values()), \"Encodings and labels lengths do not match.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = IMDBdataset(train_encodings, train_labels)\n",
        "test_dataset = IMDBdataset(test_encodings,test_labels)\n",
        "val_dataset = IMDBdataset(val_encodings, val_labels)\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model = model.to(device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c017d845-1364-4b14-fa1f-32d08103a71c",
        "id": "5PjidDGrr6Sf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "FYJUbc6Ir6Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "raw_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "raw_model = raw_model.to(device=device)\n",
        "raw_model.eval()\n",
        "\n",
        "\n",
        "# Store predictions and actual labels\n",
        "raw_predictions = []\n",
        "raw_actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        # Move tensors to the same device as the model\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)  # Only needed if you're also evaluating performance\n",
        "\n",
        "        outputs = raw_model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Assuming you're doing classification and want the highest probability class\n",
        "        logits = outputs[0]\n",
        "        raw_predicted_labels = torch.argmax(logits, dim=1)\n",
        "        raw_predictions.extend(raw_predicted_labels.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3098c031-9d0f-45a6-f9ee-d3aba4795373",
        "id": "ApsvXMO0r6Sh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 20000/20000 [06:04<00:00, 54.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_actual_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        raw_labels = batch['labels'].to(device)  # Assuming labels are on the same device\n",
        "        raw_actual_labels.extend(raw_labels.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc1b5e8-27a8-4fbc-93d7-1296026d5884",
        "id": "W5XR02owr6Si"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [00:06<00:00, 2860.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_correct_predictions = sum(p == a for p, a in zip(raw_predictions, raw_actual_labels))\n",
        "raw_accuracy = raw_correct_predictions / len(raw_predictions)\n",
        "print(f\"Accuracy: {raw_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b666b6c-1cd5-44f3-981e-c9fcd90212bc",
        "id": "9Rl5ML0br6Si"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 49.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
        "# Ensure predictions and actual_labels are numpy arrays or compatible formats\n",
        "precision = precision_score(raw_actual_labels, raw_predictions)\n",
        "recall = recall_score(raw_actual_labels, raw_predictions)\n",
        "f1 = f1_score(raw_actual_labels, raw_predictions)\n",
        "conf_matrix = confusion_matrix(raw_actual_labels, raw_predictions)\n",
        "mcc = matthews_corrcoef(raw_actual_labels, raw_predictions)\n",
        "\n",
        "# ROC-AUC score requires probability scores of the positive class, which might need model.predict_proba() or equivalent\n",
        "# If your model outputs probabilities, you can use:\n",
        "# roc_auc = roc_auc_score(actual_labels, prediction_probabilities)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.2f}\")\n",
        "# print(f\"ROC-AUC Score: {roc_auc:.2f}\")  # Uncomment if you have probability predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96d54f9-a885-4fa0-f341-ff3b0c495ad4",
        "id": "T0OEGPXcr6Si"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.50\n",
            "Recall: 0.98\n",
            "F1 Score: 0.66\n",
            "Confusion Matrix:\n",
            "[[  60 9875]\n",
            " [ 157 9908]]\n",
            "Matthews Correlation Coefficient: -0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "\n",
        "# Fit and transform the training data to create TF-IDF vectors\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
        "\n",
        "# Transform the test data to TF-IDF vectors\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_texts)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef\n",
        "\n",
        "# Initialize and train the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_tfidf, train_labels)\n",
        "\n",
        "# Predict on the test set\n",
        "nb_predictions = nb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Compute metrics\n",
        "nb_accuracy = accuracy_score(test_labels, nb_predictions)\n",
        "nb_precision = precision_score(test_labels, nb_predictions, average='binary')\n",
        "nb_recall = recall_score(test_labels, nb_predictions, average='binary')\n",
        "nb_f1 = f1_score(test_labels, nb_predictions, average='binary')\n",
        "nb_conf_matrix = confusion_matrix(test_labels, nb_predictions)\n",
        "nb_mcc = matthews_corrcoef(test_labels, nb_predictions)\n",
        "\n",
        "print(\"Naive Bayes Metrics:\")\n",
        "print(f\"Accuracy: {nb_accuracy:.4f}\")\n",
        "print(f\"Precision: {nb_precision:.4f}\")\n",
        "print(f\"Recall: {nb_recall:.4f}\")\n",
        "print(f\"F1 Score: {nb_f1:.4f}\")\n",
        "print(f\"Confusion Matrix: \\n{nb_conf_matrix}\")\n",
        "print(f\"Matthews Correlation Coefficient: {nb_mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c128e983-90b3-4e3f-fe72-98d0f85acdc2",
        "id": "V-5fSpDlr6Sj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Metrics:\n",
            "Accuracy: 0.8603\n",
            "Precision: 0.8611\n",
            "Recall: 0.8613\n",
            "F1 Score: 0.8612\n",
            "Confusion Matrix: \n",
            "[[8537 1398]\n",
            " [1396 8669]]\n",
            "Matthews Correlation Coefficient: 0.7206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tETJPxKir6Sk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}